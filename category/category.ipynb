{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RM-eg0dEiao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Flatten, Concatenate, Input, LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecXGLAUTHMEQ",
        "colab_type": "text"
      },
      "source": [
        "# 뉴스 카테고리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt_pnlx5r7W5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# json 읽어오기\n",
        "news_data = pd.read_json('./drive/My Drive/News_Category_Dataset_v2.json', lines=True)\n",
        "# print(news_data)\n",
        "\n",
        "news_data = news_data.loc[:, [\"category\", \"headline\"]]\n",
        "# print(news_data)\n",
        "\n",
        "# 카테고리 정수 인코딩\n",
        "# news_data['category'] = news_data['category'].replace(~~~~~~~, ~~~~~)\n",
        "# print(pd.factorize(news_data['category']))\n",
        "category_list = pd.factorize(news_data['category'])[1]\n",
        "news_data['category'] = pd.factorize(news_data['category'])[0]\n",
        "\n",
        "print(news_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y060Ub92G8kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정규표현식 사용\n",
        "news_data['headline'] = news_data['headline'].str.replace(\"[^\\w]\", \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2frf1Kn8G9gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split하면서 shuffle 적용\n",
        "news_train, news_test, y_train, y_test = train_test_split(news_data['headline'], news_data['category'], test_size=0.2, shuffle=True, random_state=23)\n",
        "\n",
        "# 원핫벡터로 만들어줍시다! (num_classes로 카테고리 수 명시 가능)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(len(y_train[0]))\n",
        "print(len(y_test[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egb0SZf0G-3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 토큰화 진행\n",
        "stopwords = ['a', 'an']\n",
        "\n",
        "X_train = []\n",
        "for stc in news_train:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_train.append(token)\n",
        "\n",
        "X_test = []\n",
        "for stc in news_test:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_test.append(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2TdBHcwHA7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# 헤드라인 정수인코딩\n",
        "tokenizer = Tokenizer(25000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBKVMIAPHCXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(tokenizer.word_index))\n",
        "\n",
        "wc = 0\n",
        "for word, word_count in tokenizer.word_counts.items():\n",
        "    if word_count <= 2:\n",
        "        wc += 1\n",
        "\n",
        "print(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdmyLiGHHEUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "len_stc = []\n",
        "for data in X_train:\n",
        "    len_stc.append(len(data))\n",
        "\n",
        "y, x, _ = plt.hist(len_stc, bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FlbIpERHFuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 15\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgB8_3_DHG6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(25000, 128))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(41, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loIwsdJhHIKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdsCQWOQHJb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = input()\n",
        "token_stc = sentence.split()\n",
        "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
        "\n",
        "score = model.predict(pad_stc)\n",
        "print(category_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfu2fx0uBYAN",
        "colab_type": "text"
      },
      "source": [
        "# 트위터 감정 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edlWvF6pBXSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tweet_data = pd.read_csv('./drive/My Drive/tweet_dataset.csv')\n",
        "# print(tweet_data)\n",
        "tweet_data = tweet_data.loc[: , [\"sentiment\", \"text\"]]\n",
        "# print(tweet_data)\n",
        "tweet_data = tweet_data.dropna(how='any')\n",
        "\n",
        "# 감정 인코딩\n",
        "print(pd.factorize(tweet_data['sentiment']))\n",
        "tweet_data['sentiment'] = pd.factorize(tweet_data['sentiment'])[0]\n",
        "print(tweet_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z6u9d0gDzBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정규표현식 써서 단어 아니면 삭제\n",
        "tweet_data['text'] = tweet_data['text'].str.replace(\"[^\\w]\", \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzHtJM_REGWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test/train 스플릿\n",
        "tweet_train, tweet_test, y_train, y_test = train_test_split(tweet_data['text'], tweet_data['sentiment'], test_size=0.2, shuffle=True, random_state=23)\n",
        "\n",
        "# 원핫벡터화\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(len(y_train[0]))\n",
        "print(len(y_test[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT4fkggfEXNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "# nltk stopwords 리스트\n",
        "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
        "\n",
        "# 토큰화 진행\n",
        "X_train = []\n",
        "for stc in tweet_train:\n",
        "    token = []\n",
        "    words = WordPunctTokenizer().tokenize(stc)\n",
        "    for word in words:\n",
        "        if word.lower() not in stopwords:\n",
        "            token.append(word.lower())\n",
        "    X_train.append(token)\n",
        "\n",
        "X_test = []\n",
        "for stc in tweet_test:\n",
        "    token = []\n",
        "    words = WordPunctTokenizer().tokenize(stc)\n",
        "    for word in words:\n",
        "        if word.lower() not in stopwords:\n",
        "            token.append(word.lower())\n",
        "    X_test.append(token)\n",
        "\n",
        "# print(X_train[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nhk_ybdG9QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# 트윗 정수인코딩\n",
        "tokenizer = Tokenizer(10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHgUuJFCRTAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUwhgWgKLFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(tokenizer.word_index))\n",
        "low_count = 0\n",
        "for word, word_count in tokenizer.word_counts.items():\n",
        "    if word_count > 1:\n",
        "        low_count += 1\n",
        "print(low_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pabN-n4G-Y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장의 최대 길이 구하기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "len_stc = []\n",
        "for data in X_train:\n",
        "    len_stc.append(len(data))\n",
        "\n",
        "y, x, _ = plt.hist(len_stc)\n",
        "plt.show()\n",
        "print(sum(len_stc)/len(len_stc))\n",
        "print(y.max())\n",
        "print(x.max())\n",
        "print(x[np.where(y == y.max())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnwtDL_0HACJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 25\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smdx8t8KIaMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_train[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "082QQAIUHA5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(13, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOjJ75nWK_m3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 함수형 케라스\n",
        "inputs = Input(shape=(25,))\n",
        "embed = Embedding(10000, 32)(inputs)\n",
        "drop = Dropout(0.3)(embed)\n",
        "\n",
        "# 모델 합성\n",
        "concat_layers = []\n",
        "\n",
        "conv = Conv1D(32, 1, padding='same', activation='relu')(drop)\n",
        "pool = GlobalMaxPooling1D()(conv)\n",
        "flat = Flatten()(pool)\n",
        "concat_layers.append(flat)\n",
        "\n",
        "conv = Conv1D(32, 2, padding='same', activation='relu')(drop)\n",
        "pool = GlobalMaxPooling1D()(conv)\n",
        "flat = Flatten()(pool)\n",
        "concat_layers.append(flat)\n",
        "\n",
        "conv = Conv1D(32, 3, padding='same', activation='relu')(drop)\n",
        "pool = GlobalMaxPooling1D()(conv)\n",
        "flat = Flatten()(pool)\n",
        "concat_layers.append(flat)\n",
        "######\n",
        "concat = Concatenate()(concat_layers)\n",
        "relu = Dense(64, activation='relu')(concat)\n",
        "drop = Dropout(0.5)(relu)\n",
        "\n",
        "outputs = Dense(13, activation=\"softmax\")(drop)\n",
        "\n",
        "model = Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzlQbJZxHCVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZXatJOiHDxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = input()\n",
        "# 토큰화\n",
        "token_stc = sentence.split()\n",
        "# 정수 인코딩\n",
        "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
        "# 패딩\n",
        "pad_stc = pad_sequences(encode_stc, maxlen = 25)\n",
        "\n",
        "score = model.predict(pad_stc)\n",
        "\n",
        "sent_list = ['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise', 'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger']\n",
        "\n",
        "print(sent_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}